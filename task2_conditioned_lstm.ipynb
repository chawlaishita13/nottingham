{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce1b33b",
   "metadata": {},
   "source": [
    "# ðŸŽ¼ Task 2: Conditioned Symbolic Music Generation with LSTM\n",
    "This notebook extends the Task 1 LSTM-based symbolic music generator by conditioning generation on chord tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89208a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from music21 import converter, note, chord, stream, instrument\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcc5c0",
   "metadata": {},
   "source": [
    "## ðŸ§© Helper Class for Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa913ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionedMidiLSTM:\n",
    "    def __init__(self):\n",
    "        self.note_to_int = {}\n",
    "        self.int_to_note = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def parse_midi(self, file_path):\n",
    "        midi = converter.parse(file_path)\n",
    "        notes = []\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "\n",
    "        if parts:  # file has instrument parts\n",
    "            for element in parts.parts[0].recurse():\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        return notes\n",
    "\n",
    "    def preprocess_midi_files(self, directory, max_files=None):\n",
    "        all_notes = []\n",
    "        files = list(Path(directory).rglob(\"*.mid\"))[:max_files]\n",
    "        for file in files:\n",
    "            notes = self.parse_midi(file)\n",
    "            if len(notes) > 0:\n",
    "                # Fake chord condition (could be improved)\n",
    "                chord_token = random.choice(['C', 'G', 'Am', 'F'])  \n",
    "                all_notes.extend([chord_token] + notes)\n",
    "        return all_notes\n",
    "\n",
    "    def create_vocabulary(self, notes):\n",
    "        unique_notes = sorted(set(notes))\n",
    "        self.note_to_int = {note: i for i, note in enumerate(unique_notes)}\n",
    "        self.int_to_note = {i: note for note, i in self.note_to_int.items()}\n",
    "        self.vocab_size = len(unique_notes)\n",
    "        return notes\n",
    "\n",
    "    def create_sequences(self, notes, seq_length=50):\n",
    "        inputs, targets = [], []\n",
    "        for i in range(len(notes) - seq_length):\n",
    "            seq_in = notes[i:i + seq_length]\n",
    "            seq_out = notes[i + seq_length]\n",
    "            inputs.append([self.note_to_int[n] for n in seq_in])\n",
    "            targets.append(self.note_to_int[seq_out])\n",
    "        return np.array(inputs), to_categorical(targets, num_classes=self.vocab_size)\n",
    "\n",
    "    def build_model(self, seq_length):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.vocab_size, output_dim=100, input_length=seq_length))\n",
    "        model.add(LSTM(256, return_sequences=True))\n",
    "        model.add(LSTM(256))\n",
    "        model.add(Dense(self.vocab_size, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        preds = np.log(preds + 1e-9) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        return np.random.choice(range(len(preds)), p=preds)\n",
    "\n",
    "    def generate(self, model, seed_seq, length=100):\n",
    "        result = []\n",
    "        current_seq = seed_seq.copy()\n",
    "        for _ in range(length):\n",
    "            prediction = model.predict(np.array([current_seq]), verbose=0)[0]\n",
    "            index = self.sample(prediction, temperature=0.9)\n",
    "            result.append(index)\n",
    "            current_seq = current_seq[1:] + [index]\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434da6a9",
   "metadata": {},
   "source": [
    "## ðŸš€ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b923e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_lstm = ConditionedMidiLSTM()\n",
    "\n",
    "# Load and process data\n",
    "notes = midi_lstm.preprocess_midi_files(\"nottingham-dataset/MIDI_cleaned\", max_files=30)\n",
    "filtered_notes = midi_lstm.create_vocabulary(notes)\n",
    "X, y = midi_lstm.create_sequences(filtered_notes, seq_length=50)\n",
    "\n",
    "# Split and train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "model = midi_lstm.build_model(seq_length=50)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=64)\n",
    "model.save(\"conditioned_lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bea3d5",
   "metadata": {},
   "source": [
    "## ðŸŽ¼ Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb283c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, chord, instrument\n",
    "\n",
    "# Pick a random seed sequence with a chord token at start\n",
    "start = random.randint(0, len(X) - 1)\n",
    "seed = list(X[start])\n",
    "\n",
    "# Generate indices\n",
    "generated = midi_lstm.generate(model, seed, length=100)\n",
    "generated_notes = [midi_lstm.int_to_note[idx] for idx in generated]\n",
    "\n",
    "# Convert to MIDI\n",
    "output_stream = stream.Stream()\n",
    "output_stream.append(instrument.Piano())\n",
    "for token in generated_notes:\n",
    "    if '.' in token:\n",
    "        output_stream.append(chord.Chord([int(n) for n in token.split('.')]))\n",
    "    else:\n",
    "        output_stream.append(note.Note(token))\n",
    "output_stream.write(\"midi\", fp=\"task2_generated.mid\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
